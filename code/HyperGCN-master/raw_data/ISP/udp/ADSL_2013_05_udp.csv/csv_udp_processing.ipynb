{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os, inspect, glob\n",
    "import numpy as np, scipy.sparse as sp\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv():\n",
    "    os.chdir(os.getcwd())\n",
    "    extension = 'csv'\n",
    "    all_filenames = [i for i in glob.glob('*.{extension}'.format(extension=extension))]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "    combined_csv.to_csv(\"combined_csv.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_csv()\n",
    "\n",
    "df = pd.read_csv(\"combined_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['c_asn', 'c_bytes_all', 'c_durat', 'c_first_abs', 'c_ip', 'c_isint',\n",
    "   'c_pkts_all', 'c_port', 'c_type', 's_asn', 's_bytes_all', 's_durat',\n",
    "   's_first_abs', 's_ip', 's_isint', 's_pkts_all', 's_port', 's_type']\n",
    "df['c_asn'] = pd.to_numeric(df['c_asn'], errors='coerce')\n",
    "df['s_asn'] = pd.to_numeric(df['s_asn'], errors='coerce')\n",
    "df = df[~df['c_asn'].isnull()]\n",
    "df = df[~df['s_asn'].isnull()]\n",
    "# df = df[df['c_asn'].isnumeric()]\n",
    "# df = df[df['s_asn'].isnumeric()]\n",
    "df = df.dropna(subset=['c_asn'])\n",
    "df = df.dropna(subset=['s_asn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_asn'] = df['c_asn'].astype('int32')\n",
    "df['s_asn'] = df['s_asn'].astype('int32')\n",
    "\n",
    "asn_set = set(df['c_asn']).union(set(df['s_asn']))\n",
    "asn_list= list(asn_set)\n",
    "asn_dict = {asn_list[nodeid] : nodeid for nodeid in range(len(asn_list))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hypergraph\n",
    "c_asn_ids = [asn_dict[asn] for asn in df['c_asn']]\n",
    "s_asn_ids = [asn_dict[asn] for asn in df['s_asn']]\n",
    "edges = list(zip(c_asn_ids, s_asn_ids))\n",
    "hypergraph = {i: edges[i] for i in range(len(edges))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names = ['c_asn', 'c_durat', 'c_first_abs', 'c_ip', 'c_isint', 'c_port', \n",
    "                   's_asn','s_durat', 's_first_abs', 's_ip', 's_isint', 's_port'] # select attributes name\n",
    "label_names = ['c_type'] # select label to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nodes = c_asn_ids\n",
    "attribute_mat = np.zeros((len(c_nodes), len(attribute_names)))\n",
    "for c, name in enumerate(attribute_names):\n",
    "    attribute_mat[:, c] = df[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11632x12 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 76995 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate features\n",
    "attr_dict = dict(zip(c_nodes, attribute_mat))\n",
    "attr_dict_sorted = {}\n",
    "for key in sorted(attr_dict.keys()):\n",
    "    attr_dict_sorted[key] = attr_dict[key]\n",
    "    \n",
    "features = []\n",
    "for v in range(len(attr_dict_sorted)):\n",
    "    if v in attr_dict_sorted.keys():\n",
    "        features.append(attr_dict_sorted[v])\n",
    "    else:\n",
    "        features.append(np.zeros(len(attribute_names)))\n",
    "        \n",
    "features = sp.csr_matrix(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels\n",
    "label_dict = dict(zip(c_asn_ids, df['c_type'])) #c\n",
    "label_dict_sorted = {}\n",
    "for key in sorted(label_dict.keys()):\n",
    "    label_dict_sorted[key] = label_dict[key]\n",
    "    \n",
    "labels = []\n",
    "for v in range(V):\n",
    "    if v in label_dict_sorted.keys():\n",
    "        labels.append(label_dict_sorted[v])\n",
    "    else:\n",
    "        labels.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "splits = {}\n",
    "node_sorted = list(range(V))\n",
    "random.shuffle(node_sorted)\n",
    "train_size = round(0.75*V)\n",
    "test_size = V - train_size\n",
    "train_set, test_set = train_test_split(node_sorted, train_size=train_size, test_size=test_size)\n",
    "splits['train'] = train_set\n",
    "splits['test'] = test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hypergraph.pickle\", \"wb\") as hypergraph_out:\n",
    "    pickle.dump(hypergraph, hypergraph_out)\n",
    "    hypergraph_out.close()\n",
    "with open(\"features.pickle\", \"wb\") as features_out:\n",
    "    pickle.dump(features, features_out)\n",
    "    features_out.close()\n",
    "with open(\"labels.pickle\", \"wb\") as labels_out:\n",
    "    pickle.dump(labels, labels_out)\n",
    "    labels_out.close()\n",
    "with open(\"splits.pickle\", \"wb\") as splits_out:\n",
    "    pickle.dump(splits, splits_out)\n",
    "    splits_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
